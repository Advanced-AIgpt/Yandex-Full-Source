<NNet>
    Backend CUDA
    DeviceIdx 0
    Rnn true
    ReuseAllocatedMemory false
</NNet>

<Layer>
    Name data_from_encoder
    Type data_internal
    InputDims 512
    PreprocessingType NoPreprocessing
    FixedSize true
    InputMatrixType Dense
    PrevLayerName context_lstm
    AdapterType last_state
</Layer>

<Layer>
    Name reply_data
    Type data
    SamplePartIdx 1
</Layer>

<Layer>
    Name reply_data_delayed
    Type delay
    RecurrentAncestors reply_data
</Layer>

<Layer>
    Name reply_embedding
    Type fc
    Ancestors reply_data_delayed
    NumberOfOutputs 512
    InitW 0.15
</Layer>

<Layer>
    Name reply_lstm
    Type lstm
    Ancestors reply_embedding, data_from_encoder
    NumberOfOutputs 512
    InitW bengio
    IsLastLayer true
</Layer>

<Layer>
    Name fc_intermediate_decoder
    Type fc
    Ancestors reply_lstm
    NumberOfOutputs 128
    InitW bengio
</Layer>

<Layer>
    Name fc_intermediate_activation_decoder
    Type neuron
    NeuronType tanh
    Ancestors fc_intermediate_decoder
</Layer>

<Layer>
    Name fc_decoder
    Type fc
    Ancestors fc_intermediate_activation_decoder
    NumberOfOutputs 124747
    InitW bengio
</Layer>

<Layer>
    Name cost_decoder
    Type softmax_cost_two_inputs
    Ancestors fc_decoder, reply_data
</Layer>
